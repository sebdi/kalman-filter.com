---
layout: post
title:  "Normalized Estimation Error Squared (NEES)"
permalink: /normalized-estimation-error-squared/
date:   2022-08-14 00:00:00 +0000
categories: kalman-filter
---

A desired property of a state estimator is consistency. 
A state estimator is consistent if it is able to correctly indicate the quality of the estimate. 
It should be able to do this because an increase in sample size leads to a growth in information content and the state estimate \\( \hat{\mathbf{x}}(k) \\) is as close as possible to the true state \\( \mathbf{x}(k)  \\).
This results from the requirement that a state estimator shall be unbiased.
Mathematically speaking, this is expressed by the expected value of the estimation error \\( \tilde{\mathbf{x}}(k)  \\) being zero

\\[ E [ \mathbf{x}(k) - \hat{\mathbf{x}}(k)  ] = E [ \tilde{\mathbf{x}}(k)  ] = 0 \\]

and the condition for consistency

\\[ E [ [\mathbf{x}(k) - \hat{\mathbf{x}}(k)] [\mathbf{x}(k) - \hat{\mathbf{x}}(k)]^T ] = E [ \tilde{\mathbf{x}}(k\|k) \tilde{\mathbf{x}}(k\|k)^T  ] = \mathbf{P}(k\|k) \. \\]

Checking the consistency of the state estimator can be done with a Normalized Estimation Error Squared (NEES) test.
For this purpose, a normalization of the estimation error \\( \tilde{\mathbf{x}} \\) and the error covariance matrix \\( \mathbf{P} \\) is performed

\\[ \epsilon (k) = \tilde{\mathbf{x}}(k\|k)^T \mathbf{P}(k\|k)^{-1} \tilde{\mathbf{x}}(k\|k) \ .\\]

The quantity \\( \epsilon (k) \\)  is chi-squared distributed with \\( \text{dim}( \tilde{\mathbf{x}}(k) )) = n_x \\) degrees of freedom.

*Brief explanation why chi-squared distributed: The sum of squared random variables which are normally distributed are chi-squared distributed. 
Since \\( \tilde{\mathbf{x}} \\) is the difference of two standard normal random variables, i.e. \\( \mathbf{x}(k) \\) and \\( \hat{\mathbf{x}}(k)\\), \\( \tilde{\mathbf{x}} \\) is a standard normal random variable, too. 
[Consult Wikipedia for more details.](https://en.wikipedia.org/wiki/Chi-squared_distribution)*

The above properties can now be used to check whether a state estimator delivers consistent results, i.e. whether it correctly estimates the quality of its estimation.
For this purpose, a simulation is used and the fact that the squared estimation error is chi-squared distributed.
This allows for a hypothesis test.
The statistical significance is ensured by averaging over N Monte Carlo test runs

\\[ \text{NEES}( \epsilon(k) ) = \overline{\epsilon} (k)  = \frac{1}{N} \sum^N_{i=1} \epsilon_i(k) \. \\]

\\( \overline{\epsilon}\\) has the property that the mean converges towards \\( N n_x \\) and that \\( \overline{\epsilon}\\) is chi-squared distributed with \\( N n_x \\) degrees of freedom.
The consistency test is done with a hypothesis test. 
Under the hypothesis \\( H_0 \\) that the filter is consistent, the hypothesis \\( H_0 \\) is accepted if

\\[ \overline{\epsilon} (k) \in [r_1,r_2] \. \\]

The acceptance interval is chosen such that the probability that \\( H_0 \\) is accepted is \\( (1 - \alpha) \\)

\\[ P \\{ \overline{\epsilon} (k) \in [r_1,r_2]  \| H_0 \\} = 1 - \alpha \. \\]

If the NEES is greater than the upper bound \\( r_2 \\), then the filter estimates the error to be lower than it is in reality.
Provided that the measurement noise was selected properly, the process noise was chosen too low.
If the NEES is smaller than \\( r_1 \\), then the error is estimated larger than it really is. 
In this case the filter is called inefficient. 
The process noise was chosen too large.

It is important to note that a NEES test is only statistically significant when averaged over many runs. This is easier to do in a simulation than in real life. 
In practice, it is therefore recommended to perform the [Normalized Innovation Squared (NIS)](/normalized-innovation-squared/) test exclusively or additionally.


[jekyll-docs]: https://jekyllrb.com/docs/home
[jekyll-gh]:   https://github.com/jekyll/jekyll
[jekyll-talk]: https://talk.jekyllrb.com/
